{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "077b396dd7d04b8d8b8090abfa085e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f85fdce059840a79b270918ad75a1f2",
              "IPY_MODEL_10a493cadf774378ad739591dbf44451",
              "IPY_MODEL_c497bd3a153242ed8a13ef0e22e93338"
            ],
            "layout": "IPY_MODEL_1592550c40334828910f18897a8b74d1"
          }
        },
        "8f85fdce059840a79b270918ad75a1f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77c8c2ba96f44c6e941567aa2de086b4",
            "placeholder": "​",
            "style": "IPY_MODEL_a9e7e8cc6c6b418eb32799c1899db50b",
            "value": "model.safetensors: 100%"
          }
        },
        "10a493cadf774378ad739591dbf44451": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_715f3964afcc4c02b5860b46d4434b34",
            "max": 110148080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3c0798be2784a17819c02a2dfcf32a4",
            "value": 110148080
          }
        },
        "c497bd3a153242ed8a13ef0e22e93338": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f4b3f741a73450bbb3d67fbdf32cd93",
            "placeholder": "​",
            "style": "IPY_MODEL_a465c6e9a92641c78294415209f510da",
            "value": " 110M/110M [00:00&lt;00:00, 235MB/s]"
          }
        },
        "1592550c40334828910f18897a8b74d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77c8c2ba96f44c6e941567aa2de086b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e7e8cc6c6b418eb32799c1899db50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "715f3964afcc4c02b5860b46d4434b34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3c0798be2784a17819c02a2dfcf32a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f4b3f741a73450bbb3d67fbdf32cd93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a465c6e9a92641c78294415209f510da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92d36ec708104ebc80cc7bce01eaafaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8b844ed096e4856bedc3b8f60740e05",
              "IPY_MODEL_7f24964a93a74be3a5704665c95cfd11",
              "IPY_MODEL_9ebe63404f4b4c5b9488f4581e23f01c"
            ],
            "layout": "IPY_MODEL_3814bcf9e0404378b6c31f9e5a54a68e"
          }
        },
        "c8b844ed096e4856bedc3b8f60740e05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_669720e8f1704e9fbc14f0b65c4a158d",
            "placeholder": "​",
            "style": "IPY_MODEL_5b7993171e3f4446b42540d1bff0a3e5",
            "value": "model.safetensors: 100%"
          }
        },
        "7f24964a93a74be3a5704665c95cfd11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3da2902e47904b3e9cb027ac5d099f64",
            "max": 110148080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbafeee59d4c499f9752310cebc10477",
            "value": 110148080
          }
        },
        "9ebe63404f4b4c5b9488f4581e23f01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235671a72ed14f139c9ab2ed1983b8ec",
            "placeholder": "​",
            "style": "IPY_MODEL_0809782fa87844388ef98317d843edc0",
            "value": " 110M/110M [00:00&lt;00:00, 180MB/s]"
          }
        },
        "3814bcf9e0404378b6c31f9e5a54a68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "669720e8f1704e9fbc14f0b65c4a158d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b7993171e3f4446b42540d1bff0a3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3da2902e47904b3e9cb027ac5d099f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbafeee59d4c499f9752310cebc10477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "235671a72ed14f139c9ab2ed1983b8ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0809782fa87844388ef98317d843edc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "206a6bb9bcbe44808a691b1cc0afadc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8191d28d354844ee914ca7cf146f4c88",
              "IPY_MODEL_c63bd26ab58a44f68328ce8480a099d7",
              "IPY_MODEL_dd6df9774e4641fe8375edfc38fc717d"
            ],
            "layout": "IPY_MODEL_2b95b083ef014145a96a2571918aa415"
          }
        },
        "8191d28d354844ee914ca7cf146f4c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2c1330a7f8d41b38450ef56f41cb3e1",
            "placeholder": "​",
            "style": "IPY_MODEL_aa862aa207544fa7b202c833c71d101d",
            "value": "model.safetensors: 100%"
          }
        },
        "c63bd26ab58a44f68328ce8480a099d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c93db02ceda04867b4939a6a2c884dcc",
            "max": 110148080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3964fba3fa7483eb8dd609823e9c825",
            "value": 110148080
          }
        },
        "dd6df9774e4641fe8375edfc38fc717d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a50f5ed721d4e1391d73c938e15acb3",
            "placeholder": "​",
            "style": "IPY_MODEL_44373aa4b0f0413581dda791486c55a0",
            "value": " 110M/110M [00:00&lt;00:00, 323MB/s]"
          }
        },
        "2b95b083ef014145a96a2571918aa415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2c1330a7f8d41b38450ef56f41cb3e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa862aa207544fa7b202c833c71d101d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c93db02ceda04867b4939a6a2c884dcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3964fba3fa7483eb8dd609823e9c825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a50f5ed721d4e1391d73c938e15acb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44373aa4b0f0413581dda791486c55a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLCyA7PHD8Vo",
        "outputId": "aa900165-82f4-4df8-ba7d-9f77f59807d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Path to the ZIP file\n",
        "zip_path = \"/content/drive/MyDrive/dataset_crossvit-20250331T231403Z-001.zip\"\n",
        "\n",
        "# Path to extract the dataset\n",
        "extract_to = \"/content/drive/MyDrive/dataset_crossvit\"\n",
        "\n",
        "# Function to extract the ZIP file\n",
        "def extract_zip(zip_path, extract_to):\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extracted ZIP file to {extract_to}\")\n",
        "\n",
        "# Execute extraction\n",
        "extract_zip(zip_path, extract_to)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5L37u1vEDUm",
        "outputId": "3c45bce7-c77b-43b5-aaad-68904fe4ca96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted ZIP file to /content/drive/MyDrive/dataset_crossvit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(extract_to))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En37vTzJENk5",
        "outputId": "5c40e67d-994b-4dac-9c00-6cf2da0e42af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dataset_crossvit']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Overfitting but good accuracy on train but no generalisation"
      ],
      "metadata": {
        "id": "6LxvkMGMaXkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),  # Slight color variation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    # Add small Gaussian noise\n",
        "    transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01)  # Small noise to simulate chart variations\n",
        "])"
      ],
      "metadata": {
        "id": "ADw9GtPwRlSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "I4AXVHTUR1lJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, weight=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, weight=self.weight, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss\n",
        "\n",
        "class RoboflowCocoDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "        self.category_map = {cat['id']: idx for idx, cat in enumerate(self.coco_data['categories'])}\n",
        "        self.class_names = [cat['name'] for cat in self.coco_data['categories']]\n",
        "        self.image_info = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
        "        self.annotations = {}\n",
        "        for ann in self.coco_data['annotations']:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.annotations:\n",
        "                self.annotations[img_id] = []\n",
        "            self.annotations[img_id].append(ann['category_id'])\n",
        "        self.valid_image_ids = [img_id for img_id in self.image_info.keys() if img_id in self.annotations]\n",
        "        print(f\"Total images: {len(self.image_info)}, Images with annotations: {len(self.valid_image_ids)}\")\n",
        "        missing = set(self.image_info.keys()) - set(self.annotations.keys())\n",
        "        if missing:\n",
        "            print(f\"Images missing annotations: {len(missing)}. Example IDs: {list(missing)[:5]}\")\n",
        "\n",
        "        # Class distribution\n",
        "        labels = [self.annotations[img_id][0] for img_id in self.valid_image_ids]\n",
        "        self.class_dist = Counter([self.class_names[self.category_map[l]] for l in labels])\n",
        "        print(\"Class distribution:\", self.class_dist)\n",
        "        self.labels = [self.category_map[self.annotations[img_id][0]] for img_id in self.valid_image_ids]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.valid_image_ids[idx]\n",
        "        img_path = os.path.join(self.root_dir, self.image_info[img_id])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        category_id = self.annotations[img_id][0]\n",
        "        label = self.category_map[category_id]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "jcNPxESjR2WJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import timm\n",
        "from torch.optim import Adam\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Load datasets\n",
        "train_annotation_file = os.path.join(train_dir, '_annotations.coco.json')\n",
        "valid_annotation_file = os.path.join(valid_dir, '_annotations.coco.json')\n",
        "\n",
        "train_dataset = RoboflowCocoDataset(train_dir, train_annotation_file, transform=train_transform)\n",
        "valid_dataset = RoboflowCocoDataset(valid_dir, valid_annotation_file, transform=valid_transform)\n",
        "\n",
        "# Weighted sampling for training\n",
        "class_counts = [train_dataset.class_dist[name] for name in train_dataset.class_names]\n",
        "weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
        "sample_weights = torch.tensor([weights[label] for label in train_dataset.labels], dtype=torch.float)\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Classes:\", train_dataset.class_names)\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}\")\n",
        "num_classes = len(train_dataset.class_names)\n",
        "\n",
        "# Compute class weights for Focal Loss\n",
        "total_samples = sum(class_counts)\n",
        "weights = [total_samples / (num_classes * count) for count in class_counts]\n",
        "weights = torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "model = timm.create_model('crossvit_15_240', pretrained=True, num_classes=num_classes)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(\"Model loaded on:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "077b396dd7d04b8d8b8090abfa085e34",
            "8f85fdce059840a79b270918ad75a1f2",
            "10a493cadf774378ad739591dbf44451",
            "c497bd3a153242ed8a13ef0e22e93338",
            "1592550c40334828910f18897a8b74d1",
            "77c8c2ba96f44c6e941567aa2de086b4",
            "a9e7e8cc6c6b418eb32799c1899db50b",
            "715f3964afcc4c02b5860b46d4434b34",
            "d3c0798be2784a17819c02a2dfcf32a4",
            "3f4b3f741a73450bbb3d67fbdf32cd93",
            "a465c6e9a92641c78294415209f510da"
          ]
        },
        "id": "ZFtYsnlpR7Nt",
        "outputId": "dade244d-0872-4fd9-8b60-f95c678cdcdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 1176, Images with annotations: 1170\n",
            "Images missing annotations: 6. Example IDs: [73, 747, 785, 537, 1019]\n",
            "Class distribution: Counter({'Triple Bottom Reversal': 332, 'Ascending Triangle': 211, 'Symmetric Triangle': 177, 'Descending Triangle': 114, 'Head and Shoulder': 110, 'Double Top': 84, 'Inverse Head and Shoulder': 55, 'Cup and Handle': 40, 'Double Bottom': 23, 'flag-and-pole': 22, 'Falling Wedge': 2})\n",
            "Total images: 289, Images with annotations: 288\n",
            "Images missing annotations: 1. Example IDs: [52]\n",
            "Class distribution: Counter({'Triple Bottom Reversal': 77, 'Ascending Triangle': 68, 'Symmetric Triangle': 35, 'Descending Triangle': 31, 'Double Top': 23, 'Head and Shoulder': 17, 'Inverse Head and Shoulder': 14, 'Double Bottom': 12, 'Cup and Handle': 6, 'flag-and-pole': 5})\n",
            "Classes: ['flag-and-pole', 'Ascending Triangle', 'Cup and Handle', 'Descending Triangle', 'Double Bottom', 'Double Top', 'Falling Wedge', 'Head and Shoulder', 'Inverse Head and Shoulder', 'Symmetric Triangle', 'Triple Bottom Reversal', 'flag-and-pole']\n",
            "Training samples: 1170, Validation samples: 288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/110M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "077b396dd7d04b8d8b8090abfa085e34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_loader, valid_loader, num_epochs=100, lr=0.0001):\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    criterion = FocalLoss(gamma=2.0, weight=weights.to(device)).to(device)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "\n",
        "    # Freeze backbone initially\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 10:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = True\n",
        "            print(\"Unfreezing all layers\")\n",
        "\n",
        "        model.train()\n",
        "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = correct_train / total_train\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "        val_loss /= len(valid_loader.dataset)\n",
        "        val_acc = correct_val / total_val\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "3Fet7y08R7kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate\n",
        "history = train_and_evaluate(model, train_loader, valid_loader, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySvo0M0sR75W",
        "outputId": "113d5bc7-c01f-49b0-934a-8ea26c3d7af8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 11.3297, Train Acc: 0.0718, Val Loss: 1.8051, Val Acc: 0.0000, LR: 0.000100\n",
            "Epoch 2/100, Train Loss: 10.3719, Train Acc: 0.0906, Val Loss: 1.8594, Val Acc: 0.0000, LR: 0.000100\n",
            "Epoch 3/100, Train Loss: 8.0491, Train Acc: 0.0897, Val Loss: 1.9389, Val Acc: 0.0000, LR: 0.000100\n",
            "Epoch 4/100, Train Loss: 7.3580, Train Acc: 0.0966, Val Loss: 2.0323, Val Acc: 0.0000, LR: 0.000100\n",
            "Epoch 5/100, Train Loss: 6.5509, Train Acc: 0.1009, Val Loss: 2.1067, Val Acc: 0.0000, LR: 0.000100\n",
            "Epoch 6/100, Train Loss: 5.8787, Train Acc: 0.1051, Val Loss: 2.1430, Val Acc: 0.0000, LR: 0.000100\n",
            "Epoch 7/100, Train Loss: 5.7531, Train Acc: 0.0983, Val Loss: 2.1252, Val Acc: 0.0000, LR: 0.000050\n",
            "Epoch 8/100, Train Loss: 5.7737, Train Acc: 0.0974, Val Loss: 2.1135, Val Acc: 0.0000, LR: 0.000050\n",
            "Epoch 9/100, Train Loss: 5.5885, Train Acc: 0.0863, Val Loss: 2.0953, Val Acc: 0.0000, LR: 0.000050\n",
            "Epoch 10/100, Train Loss: 5.7513, Train Acc: 0.1060, Val Loss: 2.0923, Val Acc: 0.0000, LR: 0.000050\n",
            "Unfreezing all layers\n",
            "Epoch 11/100, Train Loss: 3.3994, Train Acc: 0.1991, Val Loss: 1.8599, Val Acc: 0.0417, LR: 0.000050\n",
            "Epoch 12/100, Train Loss: 2.0558, Train Acc: 0.3017, Val Loss: 1.6848, Val Acc: 0.0521, LR: 0.000050\n",
            "Epoch 13/100, Train Loss: 1.0962, Train Acc: 0.4803, Val Loss: 1.6453, Val Acc: 0.0868, LR: 0.000050\n",
            "Epoch 14/100, Train Loss: 0.6552, Train Acc: 0.5453, Val Loss: 1.6084, Val Acc: 0.1007, LR: 0.000050\n",
            "Epoch 15/100, Train Loss: 0.3888, Train Acc: 0.5778, Val Loss: 1.6030, Val Acc: 0.1806, LR: 0.000050\n",
            "Epoch 16/100, Train Loss: 0.2792, Train Acc: 0.6530, Val Loss: 1.7308, Val Acc: 0.1944, LR: 0.000050\n",
            "Epoch 17/100, Train Loss: 0.1783, Train Acc: 0.7179, Val Loss: 1.6732, Val Acc: 0.2222, LR: 0.000050\n",
            "Epoch 18/100, Train Loss: 0.1282, Train Acc: 0.7906, Val Loss: 1.7027, Val Acc: 0.2708, LR: 0.000050\n",
            "Epoch 19/100, Train Loss: 0.0806, Train Acc: 0.8333, Val Loss: 1.8420, Val Acc: 0.3021, LR: 0.000050\n",
            "Epoch 20/100, Train Loss: 0.0598, Train Acc: 0.8615, Val Loss: 1.9851, Val Acc: 0.2917, LR: 0.000050\n",
            "Epoch 21/100, Train Loss: 0.0408, Train Acc: 0.8812, Val Loss: 2.0328, Val Acc: 0.3646, LR: 0.000025\n",
            "Epoch 22/100, Train Loss: 0.0225, Train Acc: 0.9094, Val Loss: 2.1027, Val Acc: 0.3264, LR: 0.000025\n",
            "Epoch 23/100, Train Loss: 0.0205, Train Acc: 0.9188, Val Loss: 2.0430, Val Acc: 0.3542, LR: 0.000025\n",
            "Epoch 24/100, Train Loss: 0.0136, Train Acc: 0.9385, Val Loss: 2.1345, Val Acc: 0.3438, LR: 0.000025\n",
            "Epoch 25/100, Train Loss: 0.0095, Train Acc: 0.9487, Val Loss: 2.1461, Val Acc: 0.3507, LR: 0.000025\n",
            "Epoch 26/100, Train Loss: 0.0093, Train Acc: 0.9487, Val Loss: 2.1623, Val Acc: 0.3785, LR: 0.000025\n",
            "Epoch 27/100, Train Loss: 0.0074, Train Acc: 0.9607, Val Loss: 2.1663, Val Acc: 0.3715, LR: 0.000013\n",
            "Epoch 28/100, Train Loss: 0.0054, Train Acc: 0.9735, Val Loss: 2.2191, Val Acc: 0.3681, LR: 0.000013\n",
            "Epoch 29/100, Train Loss: 0.0053, Train Acc: 0.9624, Val Loss: 2.1982, Val Acc: 0.3750, LR: 0.000013\n",
            "Epoch 30/100, Train Loss: 0.0050, Train Acc: 0.9692, Val Loss: 2.2272, Val Acc: 0.3785, LR: 0.000013\n",
            "Epoch 31/100, Train Loss: 0.0044, Train Acc: 0.9709, Val Loss: 2.2061, Val Acc: 0.3819, LR: 0.000013\n",
            "Epoch 32/100, Train Loss: 0.0037, Train Acc: 0.9709, Val Loss: 2.2090, Val Acc: 0.3681, LR: 0.000013\n",
            "Epoch 33/100, Train Loss: 0.0035, Train Acc: 0.9752, Val Loss: 2.2261, Val Acc: 0.3681, LR: 0.000006\n",
            "Epoch 34/100, Train Loss: 0.0034, Train Acc: 0.9829, Val Loss: 2.2361, Val Acc: 0.3715, LR: 0.000006\n",
            "Epoch 35/100, Train Loss: 0.0034, Train Acc: 0.9812, Val Loss: 2.2391, Val Acc: 0.3750, LR: 0.000006\n",
            "Epoch 36/100, Train Loss: 0.0033, Train Acc: 0.9821, Val Loss: 2.2328, Val Acc: 0.3611, LR: 0.000006\n",
            "Epoch 37/100, Train Loss: 0.0030, Train Acc: 0.9838, Val Loss: 2.2368, Val Acc: 0.3681, LR: 0.000006\n",
            "Epoch 38/100, Train Loss: 0.0028, Train Acc: 0.9863, Val Loss: 2.2395, Val Acc: 0.3646, LR: 0.000006\n",
            "Epoch 39/100, Train Loss: 0.0026, Train Acc: 0.9821, Val Loss: 2.2362, Val Acc: 0.3611, LR: 0.000003\n",
            "Epoch 40/100, Train Loss: 0.0027, Train Acc: 0.9829, Val Loss: 2.2377, Val Acc: 0.3576, LR: 0.000003\n",
            "Epoch 41/100, Train Loss: 0.0024, Train Acc: 0.9889, Val Loss: 2.2270, Val Acc: 0.3646, LR: 0.000003\n",
            "Epoch 42/100, Train Loss: 0.0024, Train Acc: 0.9846, Val Loss: 2.2208, Val Acc: 0.3576, LR: 0.000003\n",
            "Epoch 43/100, Train Loss: 0.0024, Train Acc: 0.9897, Val Loss: 2.2473, Val Acc: 0.3750, LR: 0.000003\n",
            "Epoch 44/100, Train Loss: 0.0024, Train Acc: 0.9872, Val Loss: 2.2385, Val Acc: 0.3715, LR: 0.000003\n",
            "Epoch 45/100, Train Loss: 0.0024, Train Acc: 0.9915, Val Loss: 2.2267, Val Acc: 0.3542, LR: 0.000002\n",
            "Epoch 46/100, Train Loss: 0.0023, Train Acc: 0.9863, Val Loss: 2.2296, Val Acc: 0.3611, LR: 0.000002\n",
            "Epoch 47/100, Train Loss: 0.0022, Train Acc: 0.9855, Val Loss: 2.2268, Val Acc: 0.3542, LR: 0.000002\n",
            "Epoch 48/100, Train Loss: 0.0022, Train Acc: 0.9923, Val Loss: 2.2278, Val Acc: 0.3646, LR: 0.000002\n",
            "Epoch 49/100, Train Loss: 0.0022, Train Acc: 0.9906, Val Loss: 2.2226, Val Acc: 0.3576, LR: 0.000002\n",
            "Epoch 50/100, Train Loss: 0.0022, Train Acc: 0.9915, Val Loss: 2.2297, Val Acc: 0.3611, LR: 0.000002\n",
            "Epoch 51/100, Train Loss: 0.0021, Train Acc: 0.9889, Val Loss: 2.2363, Val Acc: 0.3646, LR: 0.000001\n",
            "Epoch 52/100, Train Loss: 0.0022, Train Acc: 0.9846, Val Loss: 2.2359, Val Acc: 0.3681, LR: 0.000001\n",
            "Epoch 53/100, Train Loss: 0.0023, Train Acc: 0.9872, Val Loss: 2.2374, Val Acc: 0.3646, LR: 0.000001\n",
            "Epoch 54/100, Train Loss: 0.0022, Train Acc: 0.9880, Val Loss: 2.2343, Val Acc: 0.3576, LR: 0.000001\n",
            "Epoch 55/100, Train Loss: 0.0021, Train Acc: 0.9880, Val Loss: 2.2339, Val Acc: 0.3542, LR: 0.000001\n",
            "Epoch 56/100, Train Loss: 0.0022, Train Acc: 0.9872, Val Loss: 2.2329, Val Acc: 0.3576, LR: 0.000001\n",
            "Epoch 57/100, Train Loss: 0.0022, Train Acc: 0.9915, Val Loss: 2.2310, Val Acc: 0.3576, LR: 0.000000\n",
            "Epoch 58/100, Train Loss: 0.0021, Train Acc: 0.9932, Val Loss: 2.2309, Val Acc: 0.3576, LR: 0.000000\n",
            "Epoch 59/100, Train Loss: 0.0022, Train Acc: 0.9915, Val Loss: 2.2338, Val Acc: 0.3576, LR: 0.000000\n",
            "Epoch 60/100, Train Loss: 0.0020, Train Acc: 0.9940, Val Loss: 2.2339, Val Acc: 0.3576, LR: 0.000000\n",
            "Epoch 61/100, Train Loss: 0.0023, Train Acc: 0.9872, Val Loss: 2.2359, Val Acc: 0.3611, LR: 0.000000\n",
            "Epoch 62/100, Train Loss: 0.0021, Train Acc: 0.9932, Val Loss: 2.2351, Val Acc: 0.3646, LR: 0.000000\n",
            "Epoch 63/100, Train Loss: 0.0021, Train Acc: 0.9932, Val Loss: 2.2351, Val Acc: 0.3715, LR: 0.000000\n",
            "Epoch 64/100, Train Loss: 0.0023, Train Acc: 0.9838, Val Loss: 2.2350, Val Acc: 0.3611, LR: 0.000000\n",
            "Epoch 65/100, Train Loss: 0.0022, Train Acc: 0.9897, Val Loss: 2.2347, Val Acc: 0.3611, LR: 0.000000\n",
            "Epoch 66/100, Train Loss: 0.0020, Train Acc: 0.9889, Val Loss: 2.2346, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 67/100, Train Loss: 0.0019, Train Acc: 0.9940, Val Loss: 2.2343, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 68/100, Train Loss: 0.0022, Train Acc: 0.9889, Val Loss: 2.2346, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 69/100, Train Loss: 0.0022, Train Acc: 0.9838, Val Loss: 2.2346, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 70/100, Train Loss: 0.0020, Train Acc: 0.9923, Val Loss: 2.2354, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 71/100, Train Loss: 0.0021, Train Acc: 0.9915, Val Loss: 2.2354, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 72/100, Train Loss: 0.0022, Train Acc: 0.9863, Val Loss: 2.2357, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 73/100, Train Loss: 0.0019, Train Acc: 0.9923, Val Loss: 2.2357, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 74/100, Train Loss: 0.0021, Train Acc: 0.9923, Val Loss: 2.2351, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 75/100, Train Loss: 0.0020, Train Acc: 0.9923, Val Loss: 2.2351, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 76/100, Train Loss: 0.0021, Train Acc: 0.9906, Val Loss: 2.2354, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 77/100, Train Loss: 0.0020, Train Acc: 0.9906, Val Loss: 2.2354, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 78/100, Train Loss: 0.0021, Train Acc: 0.9906, Val Loss: 2.2353, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 79/100, Train Loss: 0.0020, Train Acc: 0.9932, Val Loss: 2.2353, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 80/100, Train Loss: 0.0021, Train Acc: 0.9932, Val Loss: 2.2355, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 81/100, Train Loss: 0.0022, Train Acc: 0.9906, Val Loss: 2.2357, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 82/100, Train Loss: 0.0021, Train Acc: 0.9923, Val Loss: 2.2358, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 83/100, Train Loss: 0.0021, Train Acc: 0.9897, Val Loss: 2.2359, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 84/100, Train Loss: 0.0022, Train Acc: 0.9872, Val Loss: 2.2358, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 85/100, Train Loss: 0.0022, Train Acc: 0.9897, Val Loss: 2.2358, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 86/100, Train Loss: 0.0022, Train Acc: 0.9915, Val Loss: 2.2359, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 87/100, Train Loss: 0.0020, Train Acc: 0.9906, Val Loss: 2.2359, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 88/100, Train Loss: 0.0020, Train Acc: 0.9940, Val Loss: 2.2360, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 89/100, Train Loss: 0.0021, Train Acc: 0.9906, Val Loss: 2.2359, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 90/100, Train Loss: 0.0021, Train Acc: 0.9889, Val Loss: 2.2359, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 91/100, Train Loss: 0.0022, Train Acc: 0.9897, Val Loss: 2.2361, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 92/100, Train Loss: 0.0022, Train Acc: 0.9880, Val Loss: 2.2362, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 93/100, Train Loss: 0.0020, Train Acc: 0.9932, Val Loss: 2.2362, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 94/100, Train Loss: 0.0021, Train Acc: 0.9880, Val Loss: 2.2361, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 95/100, Train Loss: 0.0021, Train Acc: 0.9923, Val Loss: 2.2360, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 96/100, Train Loss: 0.0021, Train Acc: 0.9923, Val Loss: 2.2361, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 97/100, Train Loss: 0.0021, Train Acc: 0.9889, Val Loss: 2.2362, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 98/100, Train Loss: 0.0020, Train Acc: 0.9906, Val Loss: 2.2361, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 99/100, Train Loss: 0.0021, Train Acc: 0.9880, Val Loss: 2.2362, Val Acc: 0.3542, LR: 0.000000\n",
            "Epoch 100/100, Train Loss: 0.0022, Train Acc: 0.9897, Val Loss: 2.2362, Val Acc: 0.3542, LR: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0kpPjd55R78A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NMeWUboUaf7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wL4wRFRPaf-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iNBWgTCnagBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Almost balanced but still overfitting\n"
      ],
      "metadata": {
        "id": "SP70R2L_fg_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import timm\n",
        "from torch.optim import Adam\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/dataset_crossvit/extracted/train'\n",
        "valid_dir = '/content/drive/MyDrive/dataset_crossvit/extracted/valid'"
      ],
      "metadata": {
        "id": "HmftsE0G8Hfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01)  # Corrected syntax\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n"
      ],
      "metadata": {
        "id": "2G0qvwrR8Hkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=1.0, weight=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma  # Reduced gamma to lessen focus on hard examples\n",
        "        self.weight = weight\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, weight=self.weight, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss\n",
        "\n",
        "class RoboflowCocoDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "        self.category_map = {cat['id']: idx for idx, cat in enumerate(self.coco_data['categories'])}\n",
        "        self.class_names = [cat['name'] for cat in self.coco_data['categories']]\n",
        "        self.image_info = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
        "        self.annotations = {}\n",
        "        for ann in self.coco_data['annotations']:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.annotations:\n",
        "                self.annotations[img_id] = []\n",
        "            self.annotations[img_id].append(ann['category_id'])\n",
        "        self.valid_image_ids = [img_id for img_id in self.image_info.keys() if img_id in self.annotations]\n",
        "        print(f\"Total images: {len(self.image_info)}, Images with annotations: {len(self.valid_image_ids)}\")\n",
        "        missing = set(self.image_info.keys()) - set(self.annotations.keys())\n",
        "        if missing:\n",
        "            print(f\"Images missing annotations: {len(missing)}. Example IDs: {list(missing)[:5]}\")\n",
        "\n",
        "        labels = [self.annotations[img_id][0] for img_id in self.valid_image_ids]\n",
        "        self.class_dist = Counter([self.class_names[self.category_map[l]] for l in labels])\n",
        "        print(\"Class distribution:\", self.class_dist)\n",
        "        self.labels = [self.category_map[self.annotations[img_id][0]] for img_id in self.valid_image_ids]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.valid_image_ids[idx]\n",
        "        img_path = os.path.join(self.root_dir, self.image_info[img_id])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        category_id = self.annotations[img_id][0]\n",
        "        label = self.category_map[category_id]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "S2gsM85r8Hoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_annotation_file = os.path.join(train_dir, '_annotations.coco.json')\n",
        "valid_annotation_file = os.path.join(valid_dir, '_annotations.coco.json')\n",
        "\n",
        "train_dataset = RoboflowCocoDataset(train_dir, train_annotation_file, transform=train_transform)\n",
        "valid_dataset = RoboflowCocoDataset(valid_dir, valid_annotation_file, transform=valid_transform)\n",
        "\n",
        "# Adjusted weighted sampling\n",
        "class_counts = [train_dataset.class_dist[name] for name in train_dataset.class_names]\n",
        "weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
        "# Soften the weights to reduce aggressive oversampling\n",
        "weights = weights ** 0.5  # Square root to reduce the effect\n",
        "sample_weights = torch.tensor([weights[label] for label in train_dataset.labels], dtype=torch.float)\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Classes:\", train_dataset.class_names)\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}\")\n",
        "num_classes = len(train_dataset.class_names)\n",
        "\n",
        "# Compute class weights for Focal Loss\n",
        "total_samples = sum(class_counts)\n",
        "weights = [total_samples / (num_classes * count) for count in class_counts]\n",
        "weights = torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "# Add dropout to the model\n",
        "model = timm.create_model('crossvit_15_240', pretrained=True, num_classes=num_classes, drop_rate=0.3)  # Add dropout\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(\"Model loaded on:\", device)"
      ],
      "metadata": {
        "id": "jGc3wQgr8HuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_loader, valid_loader, num_epochs=100, lr=0.0001):\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-3)  # Increased weight decay\n",
        "    criterion = FocalLoss(gamma=1.0, weight=weights.to(device)).to(device)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Freeze backbone initially\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 10:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = True\n",
        "            print(\"Unfreezing all layers\")\n",
        "\n",
        "        model.train()\n",
        "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = correct_train / total_train\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        val_loss /= len(valid_loader.dataset)\n",
        "        val_acc = correct_val / total_val\n",
        "        val_f1 = f1_score(all_labels, all_preds, average='weighted')  # Weighted F1-score for imbalance\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}, \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            # Save the best model\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "Txs4Hlk18HwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate\n",
        "history = train_and_evaluate(model, train_loader, valid_loader, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837,
          "referenced_widgets": [
            "92d36ec708104ebc80cc7bce01eaafaa",
            "c8b844ed096e4856bedc3b8f60740e05",
            "7f24964a93a74be3a5704665c95cfd11",
            "9ebe63404f4b4c5b9488f4581e23f01c",
            "3814bcf9e0404378b6c31f9e5a54a68e",
            "669720e8f1704e9fbc14f0b65c4a158d",
            "5b7993171e3f4446b42540d1bff0a3e5",
            "3da2902e47904b3e9cb027ac5d099f64",
            "cbafeee59d4c499f9752310cebc10477",
            "235671a72ed14f139c9ab2ed1983b8ec",
            "0809782fa87844388ef98317d843edc0"
          ]
        },
        "id": "4PMbjPHXagFz",
        "outputId": "87f2279a-2ba4-4e27-99d4-af3396a0c9df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 1176, Images with annotations: 1170\n",
            "Images missing annotations: 6. Example IDs: [73, 747, 785, 537, 1019]\n",
            "Class distribution: Counter({'Triple Bottom Reversal': 332, 'Ascending Triangle': 211, 'Symmetric Triangle': 177, 'Descending Triangle': 114, 'Head and Shoulder': 110, 'Double Top': 84, 'Inverse Head and Shoulder': 55, 'Cup and Handle': 40, 'Double Bottom': 23, 'flag-and-pole': 22, 'Falling Wedge': 2})\n",
            "Total images: 289, Images with annotations: 288\n",
            "Images missing annotations: 1. Example IDs: [52]\n",
            "Class distribution: Counter({'Triple Bottom Reversal': 77, 'Ascending Triangle': 68, 'Symmetric Triangle': 35, 'Descending Triangle': 31, 'Double Top': 23, 'Head and Shoulder': 17, 'Inverse Head and Shoulder': 14, 'Double Bottom': 12, 'Cup and Handle': 6, 'flag-and-pole': 5})\n",
            "Classes: ['flag-and-pole', 'Ascending Triangle', 'Cup and Handle', 'Descending Triangle', 'Double Bottom', 'Double Top', 'Falling Wedge', 'Head and Shoulder', 'Inverse Head and Shoulder', 'Symmetric Triangle', 'Triple Bottom Reversal', 'flag-and-pole']\n",
            "Training samples: 1170, Validation samples: 288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/110M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92d36ec708104ebc80cc7bce01eaafaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on: cuda\n",
            "Epoch 1/100, Train Loss: 4.0880, Train Acc: 0.0744, Val Loss: 1.9283, Val Acc: 0.0382, Val F1: 0.0043, LR: 0.000100\n",
            "Epoch 2/100, Train Loss: 4.3058, Train Acc: 0.0444, Val Loss: 1.9244, Val Acc: 0.0347, Val F1: 0.0040, LR: 0.000100\n",
            "Epoch 3/100, Train Loss: 3.8988, Train Acc: 0.0496, Val Loss: 1.9131, Val Acc: 0.0417, Val F1: 0.0048, LR: 0.000100\n",
            "Epoch 4/100, Train Loss: 4.4357, Train Acc: 0.0547, Val Loss: 1.9037, Val Acc: 0.0417, Val F1: 0.0049, LR: 0.000100\n",
            "Epoch 5/100, Train Loss: 4.3833, Train Acc: 0.0607, Val Loss: 1.9060, Val Acc: 0.0347, Val F1: 0.0042, LR: 0.000100\n",
            "Epoch 6/100, Train Loss: 4.1961, Train Acc: 0.0650, Val Loss: 1.9059, Val Acc: 0.0347, Val F1: 0.0041, LR: 0.000100\n",
            "Epoch 7/100, Train Loss: 3.6558, Train Acc: 0.0564, Val Loss: 1.9047, Val Acc: 0.0312, Val F1: 0.0045, LR: 0.000100\n",
            "Epoch 8/100, Train Loss: 4.3485, Train Acc: 0.0667, Val Loss: 1.9109, Val Acc: 0.0278, Val F1: 0.0047, LR: 0.000100\n",
            "Epoch 9/100, Train Loss: 4.0366, Train Acc: 0.0513, Val Loss: 1.9055, Val Acc: 0.0382, Val F1: 0.0047, LR: 0.000100\n",
            "Epoch 10/100, Train Loss: 3.9603, Train Acc: 0.0564, Val Loss: 1.9038, Val Acc: 0.0312, Val F1: 0.0043, LR: 0.000050\n",
            "Unfreezing all layers\n",
            "Epoch 11/100, Train Loss: 3.7044, Train Acc: 0.0607, Val Loss: 1.8575, Val Acc: 0.0417, Val F1: 0.0048, LR: 0.000050\n",
            "Epoch 12/100, Train Loss: 2.6452, Train Acc: 0.0872, Val Loss: 1.8419, Val Acc: 0.0382, Val F1: 0.0210, LR: 0.000050\n",
            "Epoch 13/100, Train Loss: 2.3491, Train Acc: 0.1103, Val Loss: 1.7650, Val Acc: 0.0625, Val F1: 0.0144, LR: 0.000050\n",
            "Epoch 14/100, Train Loss: 1.8806, Train Acc: 0.2368, Val Loss: 1.6637, Val Acc: 0.0972, Val F1: 0.0659, LR: 0.000050\n",
            "Epoch 15/100, Train Loss: 1.3831, Train Acc: 0.3265, Val Loss: 1.6819, Val Acc: 0.1840, Val F1: 0.1543, LR: 0.000050\n",
            "Epoch 16/100, Train Loss: 1.0459, Train Acc: 0.3855, Val Loss: 1.6502, Val Acc: 0.1875, Val F1: 0.1515, LR: 0.000050\n",
            "Epoch 17/100, Train Loss: 0.7917, Train Acc: 0.4769, Val Loss: 1.6730, Val Acc: 0.2222, Val F1: 0.1958, LR: 0.000050\n",
            "Epoch 18/100, Train Loss: 0.5798, Train Acc: 0.5761, Val Loss: 1.6801, Val Acc: 0.2500, Val F1: 0.2302, LR: 0.000050\n",
            "Epoch 19/100, Train Loss: 0.4182, Train Acc: 0.6513, Val Loss: 1.7582, Val Acc: 0.2604, Val F1: 0.2750, LR: 0.000050\n",
            "Epoch 20/100, Train Loss: 0.3350, Train Acc: 0.7103, Val Loss: 1.9023, Val Acc: 0.3160, Val F1: 0.2905, LR: 0.000050\n",
            "Epoch 21/100, Train Loss: 0.2420, Train Acc: 0.7795, Val Loss: 2.0606, Val Acc: 0.2882, Val F1: 0.2747, LR: 0.000050\n",
            "Epoch 22/100, Train Loss: 0.1783, Train Acc: 0.8205, Val Loss: 2.0634, Val Acc: 0.2917, Val F1: 0.2965, LR: 0.000025\n",
            "Epoch 23/100, Train Loss: 0.1231, Train Acc: 0.8641, Val Loss: 2.0859, Val Acc: 0.3368, Val F1: 0.3362, LR: 0.000025\n",
            "Epoch 24/100, Train Loss: 0.0770, Train Acc: 0.9205, Val Loss: 2.1775, Val Acc: 0.3229, Val F1: 0.3286, LR: 0.000025\n",
            "Epoch 25/100, Train Loss: 0.0634, Train Acc: 0.9248, Val Loss: 2.1773, Val Acc: 0.3299, Val F1: 0.3351, LR: 0.000025\n",
            "Epoch 26/100, Train Loss: 0.0435, Train Acc: 0.9427, Val Loss: 2.3847, Val Acc: 0.3611, Val F1: 0.3523, LR: 0.000025\n",
            "Early stopping at epoch 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import timm\n",
        "from torch.optim import Adam\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/dataset_crossvit/dataset_crossvit/extracted/train'\n",
        "valid_dir = '/content/drive/MyDrive/dataset_crossvit/dataset_crossvit/extracted/valid'\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01)\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=1.0, weight=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.weight = weight\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, weight=self.weight, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss\n",
        "\n",
        "class RoboflowCocoDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "        self.category_map = {cat['id']: idx for idx, cat in enumerate(self.coco_data['categories'])}\n",
        "        self.class_names = [cat['name'] for cat in self.coco_data['categories']]\n",
        "        self.image_info = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
        "        self.annotations = {}\n",
        "        for ann in self.coco_data['annotations']:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.annotations:\n",
        "                self.annotations[img_id] = []\n",
        "            self.annotations[img_id].append(ann['category_id'])\n",
        "        self.valid_image_ids = [img_id for img_id in self.image_info.keys() if img_id in self.annotations]\n",
        "        print(f\"Total images: {len(self.image_info)}, Images with annotations: {len(self.valid_image_ids)}\")\n",
        "        missing = set(self.image_info.keys()) - set(self.annotations.keys())\n",
        "        if missing:\n",
        "            print(f\"Images missing annotations: {len(missing)}. Example IDs: {list(missing)[:5]}\")\n",
        "\n",
        "        labels = [self.annotations[img_id][0] for img_id in self.valid_image_ids]\n",
        "        self.class_dist = Counter([self.class_names[self.category_map[l]] for l in labels])\n",
        "        print(\"Class distribution:\", self.class_dist)\n",
        "        self.labels = [self.category_map[self.annotations[img_id][0]] for img_id in self.valid_image_ids]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.valid_image_ids[idx]\n",
        "        img_path = os.path.join(self.root_dir, self.image_info[img_id])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        category_id = self.annotations[img_id][0]\n",
        "        label = self.category_map[category_id]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Load datasets\n",
        "train_annotation_file = os.path.join(train_dir, '_annotations.coco.json')\n",
        "valid_annotation_file = os.path.join(valid_dir, '_annotations.coco.json')\n",
        "\n",
        "train_dataset = RoboflowCocoDataset(train_dir, train_annotation_file, transform=train_transform)\n",
        "valid_dataset = RoboflowCocoDataset(valid_dir, valid_annotation_file, transform=valid_transform)\n",
        "\n",
        "# Adjusted weighted sampling\n",
        "class_counts = [train_dataset.class_dist[name] for name in train_dataset.class_names]\n",
        "weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
        "weights = weights ** 0.5  # Adjusted back to 0.5 for better balance\n",
        "sample_weights = torch.tensor([weights[label] for label in train_dataset.labels], dtype=torch.float)\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=4)  # Increased num_workers\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "print(\"Classes:\", train_dataset.class_names)\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}\")\n",
        "num_classes = len(train_dataset.class_names)\n",
        "\n",
        "# Compute class weights for Focal Loss\n",
        "total_samples = sum(class_counts)\n",
        "weights = [total_samples / (num_classes * count) for count in class_counts]\n",
        "weights = torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "# Use a smaller CrossViT model to reduce training time\n",
        "model = timm.create_model('crossvit_15_240', pretrained=True, num_classes=num_classes, drop_rate=0.3)  # Reduced dropout\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(\"Model loaded on:\", device)\n",
        "\n",
        "def train_and_evaluate(model, train_loader, valid_loader, num_epochs=100, lr=0.0001):\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=1e-3)  # Reduced weight decay\n",
        "    criterion = FocalLoss(gamma=1.0, weight=weights.to(device)).to(device)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "\n",
        "    # Early stopping parameters\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Freeze backbone initially\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 10:\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = True\n",
        "            print(\"Unfreezing all layers\")\n",
        "            optimizer.param_groups[0]['lr'] = 0.00005  # Slightly higher learning rate\n",
        "\n",
        "        model.train()\n",
        "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = correct_train / total_train\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        val_loss /= len(valid_loader.dataset)\n",
        "        val_acc = correct_val / total_val\n",
        "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "        # Per-class F1-scores\n",
        "        per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}, \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        print(\"Per-class F1-scores:\", {train_dataset.class_names[i]: f1 for i, f1 in enumerate(per_class_f1)})\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return history\n",
        "\n",
        "# Train and Evaluate\n",
        "history = train_and_evaluate(model, train_loader, valid_loader, num_epochs=100)"
      ],
      "metadata": {
        "id": "RgFgPo77fnIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5a668b-9f78-4458-b32e-6953e6a697ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 1176, Images with annotations: 1170\n",
            "Images missing annotations: 6. Example IDs: [73, 747, 785, 537, 1019]\n",
            "Class distribution: Counter({'Triple Bottom Reversal': 332, 'Ascending Triangle': 211, 'Symmetric Triangle': 177, 'Descending Triangle': 114, 'Head and Shoulder': 110, 'Double Top': 84, 'Inverse Head and Shoulder': 55, 'Cup and Handle': 40, 'Double Bottom': 23, 'flag-and-pole': 22, 'Falling Wedge': 2})\n",
            "Total images: 289, Images with annotations: 288\n",
            "Images missing annotations: 1. Example IDs: [52]\n",
            "Class distribution: Counter({'Triple Bottom Reversal': 77, 'Ascending Triangle': 68, 'Symmetric Triangle': 35, 'Descending Triangle': 31, 'Double Top': 23, 'Head and Shoulder': 17, 'Inverse Head and Shoulder': 14, 'Double Bottom': 12, 'Cup and Handle': 6, 'flag-and-pole': 5})\n",
            "Classes: ['flag-and-pole', 'Ascending Triangle', 'Cup and Handle', 'Descending Triangle', 'Double Bottom', 'Double Top', 'Falling Wedge', 'Head and Shoulder', 'Inverse Head and Shoulder', 'Symmetric Triangle', 'Triple Bottom Reversal', 'flag-and-pole']\n",
            "Training samples: 1170, Validation samples: 288\n",
            "Model loaded on: cuda\n",
            "Epoch 1/100, Train Loss: 4.6287, Train Acc: 0.0940, Val Loss: 1.9558, Val Acc: 0.0243, Val F1: 0.0026, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.038314176245210725), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.10526315789473684)}\n",
            "Epoch 2/100, Train Loss: 4.6074, Train Acc: 0.0556, Val Loss: 1.9510, Val Acc: 0.0208, Val F1: 0.0013, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.02247191011235955), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.04784688995215311)}\n",
            "Epoch 3/100, Train Loss: 3.7046, Train Acc: 0.0504, Val Loss: 1.9337, Val Acc: 0.0243, Val F1: 0.0020, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.04291845493562232), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.06451612903225806)}\n",
            "Epoch 4/100, Train Loss: 4.1071, Train Acc: 0.0709, Val Loss: 1.9289, Val Acc: 0.0243, Val F1: 0.0061, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.041666666666666664), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.125), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 5/100, Train Loss: 4.2101, Train Acc: 0.0581, Val Loss: 1.9260, Val Acc: 0.0312, Val F1: 0.0066, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.04975124378109453), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.10526315789473684), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.06593406593406594)}\n",
            "Epoch 6/100, Train Loss: 3.6247, Train Acc: 0.0564, Val Loss: 1.9201, Val Acc: 0.0208, Val F1: 0.0015, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.03773584905660377), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.040983606557377046)}\n",
            "Epoch 7/100, Train Loss: 4.2746, Train Acc: 0.0462, Val Loss: 1.9135, Val Acc: 0.0312, Val F1: 0.0047, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0625), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.064), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.044444444444444446)}\n",
            "Epoch 8/100, Train Loss: 4.4513, Train Acc: 0.0667, Val Loss: 1.9194, Val Acc: 0.0312, Val F1: 0.0048, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.04878048780487805), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.06060606060606061), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.07017543859649122)}\n",
            "Epoch 9/100, Train Loss: 4.1426, Train Acc: 0.0684, Val Loss: 1.9148, Val Acc: 0.0278, Val F1: 0.0043, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.03305785123966942), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.06060606060606061), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.06369426751592357)}\n",
            "Epoch 10/100, Train Loss: 3.9438, Train Acc: 0.0538, Val Loss: 1.9128, Val Acc: 0.0174, Val F1: 0.0007, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.03937007874015748)}\n",
            "Unfreezing all layers\n",
            "Epoch 11/100, Train Loss: 4.1620, Train Acc: 0.0410, Val Loss: 1.9554, Val Acc: 0.0243, Val F1: 0.0038, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.09090909090909091), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0), 'Triple Bottom Reversal': np.float64(0.0)}\n",
            "Epoch 12/100, Train Loss: 3.3252, Train Acc: 0.0769, Val Loss: 1.7892, Val Acc: 0.0451, Val F1: 0.0055, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.08583690987124463), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.1111111111111111)}\n",
            "Epoch 13/100, Train Loss: 2.7621, Train Acc: 0.1453, Val Loss: 1.8629, Val Acc: 0.0451, Val F1: 0.0201, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.06993006993006994), 'Cup and Handle': np.float64(0.11764705882352941), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.08), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.07042253521126761)}\n",
            "Epoch 14/100, Train Loss: 2.0368, Train Acc: 0.2248, Val Loss: 1.7350, Val Acc: 0.0660, Val F1: 0.0495, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.056338028169014086), 'Ascending Triangle': np.float64(0.08695652173913043), 'Cup and Handle': np.float64(0.058823529411764705), 'Descending Triangle': np.float64(0.04081632653061224), 'Double Bottom': np.float64(0.19607843137254902), 'Double Top': np.float64(0.08333333333333333), 'Falling Wedge': np.float64(0.09523809523809523), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.06802721088435375)}\n",
            "Epoch 15/100, Train Loss: 1.5350, Train Acc: 0.3248, Val Loss: 1.7020, Val Acc: 0.1354, Val F1: 0.1262, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.15), 'Ascending Triangle': np.float64(0.05970149253731343), 'Cup and Handle': np.float64(0.44), 'Descending Triangle': np.float64(0.05128205128205128), 'Double Bottom': np.float64(0.2222222222222222), 'Double Top': np.float64(0.22641509433962265), 'Falling Wedge': np.float64(0.16901408450704225), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0425531914893617)}\n",
            "Epoch 16/100, Train Loss: 1.1048, Train Acc: 0.4248, Val Loss: 1.7349, Val Acc: 0.1736, Val F1: 0.1552, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.1956521739130435), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.47619047619047616), 'Descending Triangle': np.float64(0.07692307692307693), 'Double Bottom': np.float64(0.358974358974359), 'Double Top': np.float64(0.06451612903225806), 'Falling Wedge': np.float64(0.17582417582417584), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.05063291139240506), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 17/100, Train Loss: 0.8495, Train Acc: 0.4590, Val Loss: 1.7972, Val Acc: 0.1840, Val F1: 0.1496, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.358974358974359), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.15384615384615385), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3333333333333333), 'Double Top': np.float64(0.19047619047619047), 'Falling Wedge': np.float64(0.21505376344086022), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 18/100, Train Loss: 0.6247, Train Acc: 0.5350, Val Loss: 1.7671, Val Acc: 0.2188, Val F1: 0.1843, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.3392857142857143), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.5396825396825397), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.36585365853658536), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.18691588785046728), 'Head and Shoulder': np.float64(0.06451612903225806), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 19/100, Train Loss: 0.4687, Train Acc: 0.6333, Val Loss: 1.9795, Val Acc: 0.2396, Val F1: 0.2171, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.37037037037037035), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.3508771929824561), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.4074074074074074), 'Double Top': np.float64(0.208955223880597), 'Falling Wedge': np.float64(0.11594202898550725), 'Head and Shoulder': np.float64(0.08163265306122448), 'Inverse Head and Shoulder': np.float64(0.11764705882352941), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 20/100, Train Loss: 0.3274, Train Acc: 0.7009, Val Loss: 1.9827, Val Acc: 0.2708, Val F1: 0.2846, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.32786885245901637), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.35714285714285715), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.4166666666666667), 'Double Top': np.float64(0.3181818181818182), 'Falling Wedge': np.float64(0.09523809523809523), 'Head and Shoulder': np.float64(0.11904761904761904), 'Inverse Head and Shoulder': np.float64(0.36507936507936506), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 21/100, Train Loss: 0.2348, Train Acc: 0.7632, Val Loss: 2.1111, Val Acc: 0.2604, Val F1: 0.2594, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.35714285714285715), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.463768115942029), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.4727272727272727), 'Double Top': np.float64(0.18604651162790697), 'Falling Wedge': np.float64(0.12), 'Head and Shoulder': np.float64(0.15503875968992248), 'Inverse Head and Shoulder': np.float64(0.1935483870967742), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 22/100, Train Loss: 0.1713, Train Acc: 0.8171, Val Loss: 2.1663, Val Acc: 0.2986, Val F1: 0.3032, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.3945578231292517), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.4262295081967213), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3829787234042553), 'Double Top': np.float64(0.2641509433962264), 'Falling Wedge': np.float64(0.10526315789473684), 'Head and Shoulder': np.float64(0.14285714285714285), 'Inverse Head and Shoulder': np.float64(0.35714285714285715), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 23/100, Train Loss: 0.1236, Train Acc: 0.8504, Val Loss: 2.1973, Val Acc: 0.2882, Val F1: 0.3006, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.4166666666666667), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.38461538461538464), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.36363636363636365), 'Double Top': np.float64(0.20512820512820512), 'Falling Wedge': np.float64(0.09090909090909091), 'Head and Shoulder': np.float64(0.15841584158415842), 'Inverse Head and Shoulder': np.float64(0.358974358974359), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 24/100, Train Loss: 0.0947, Train Acc: 0.8966, Val Loss: 2.2072, Val Acc: 0.3333, Val F1: 0.3432, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.3969465648854962), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.4411764705882353), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.43478260869565216), 'Double Top': np.float64(0.2127659574468085), 'Falling Wedge': np.float64(0.10810810810810811), 'Head and Shoulder': np.float64(0.15555555555555556), 'Inverse Head and Shoulder': np.float64(0.4881889763779528), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Epoch 25/100, Train Loss: 0.0667, Train Acc: 0.9308, Val Loss: 2.3512, Val Acc: 0.3403, Val F1: 0.3210, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.4945054945054945), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.37735849056603776), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3404255319148936), 'Double Top': np.float64(0.05555555555555555), 'Falling Wedge': np.float64(0.10256410256410256), 'Head and Shoulder': np.float64(0.037037037037037035), 'Inverse Head and Shoulder': np.float64(0.4626865671641791), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Early stopping at epoch 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Still overfitting\n"
      ],
      "metadata": {
        "id": "Evj3mpWD8ir9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import timm\n",
        "from torch.optim import Adam\n",
        "from PIL import Image\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.cuda.amp import GradScaler, autocast  # For mixed precision training\n",
        "\n",
        "train_dir = '/content/drive/MyDrive/dataset_crossvit/dataset_crossvit/extracted/train'\n",
        "valid_dir = '/content/drive/MyDrive/dataset_crossvit/dataset_crossvit/extracted/valid'\n"
      ],
      "metadata": {
        "id": "EI6TCYIp8ogG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    transforms.Lambda(lambda x: x + torch.randn_like(x) * 0.01)\n",
        "])\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "78ONgian8on3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2.0, weight=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma  # Increased gamma to focus on hard examples\n",
        "        self.weight = weight\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, weight=self.weight, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        return focal_loss\n",
        "\n",
        "class RoboflowCocoDataset(Dataset):\n",
        "    def __init__(self, root_dir, annotation_file, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        with open(annotation_file, 'r') as f:\n",
        "            self.coco_data = json.load(f)\n",
        "        self.category_map = {cat['id']: idx for idx, cat in enumerate(self.coco_data['categories'])}\n",
        "        self.class_names = [cat['name'] for cat in self.coco_data['categories']]\n",
        "        self.image_info = {img['id']: img['file_name'] for img in self.coco_data['images']}\n",
        "        self.annotations = {}\n",
        "        for ann in self.coco_data['annotations']:\n",
        "            img_id = ann['image_id']\n",
        "            if img_id not in self.annotations:\n",
        "                self.annotations[img_id] = []\n",
        "            self.annotations[img_id].append(ann['category_id'])\n",
        "        self.valid_image_ids = [img_id for img_id in self.image_info.keys() if img_id in self.annotations]\n",
        "        print(f\"Total images: {len(self.image_info)}, Images with annotations: {len(self.valid_image_ids)}\")\n",
        "        missing = set(self.image_info.keys()) - set(self.annotations.keys())\n",
        "        if missing:\n",
        "            print(f\"Images missing annotations: {len(missing)}. Example IDs: {list(missing)[:5]}\")\n",
        "\n",
        "        labels = [self.annotations[img_id][0] for img_id in self.valid_image_ids]\n",
        "        self.class_dist = Counter([self.class_names[self.category_map[l]] for l in labels])\n",
        "        print(\"Class distribution:\", self.class_dist)\n",
        "        self.labels = [self.category_map[self.annotations[img_id][0]] for img_id in self.valid_image_ids]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.valid_image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_id = self.valid_image_ids[idx]\n",
        "        img_path = os.path.join(self.root_dir, self.image_info[img_id])\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        category_id = self.annotations[img_id][0]\n",
        "        label = self.category_map[category_id]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "q-AvvyhJ8oqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "train_annotation_file = os.path.join(train_dir, '_annotations.coco.json')\n",
        "valid_annotation_file = os.path.join(valid_dir, '_annotations.coco.json')\n",
        "\n",
        "train_dataset = RoboflowCocoDataset(train_dir, train_annotation_file, transform=train_transform)\n",
        "valid_dataset = RoboflowCocoDataset(valid_dir, valid_annotation_file, transform=valid_transform)\n",
        "\n",
        "# Adjusted weighted sampling\n",
        "class_counts = [train_dataset.class_dist[name] for name in train_dataset.class_names]\n",
        "weights = 1.0 / torch.tensor(class_counts, dtype=torch.float)\n",
        "weights = weights ** 0.4  # Further softened weights\n",
        "sample_weights = torch.tensor([weights[label] for label in train_dataset.labels], dtype=torch.float)\n",
        "sampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler, num_workers=2)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Classes:\", train_dataset.class_names)\n",
        "print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(valid_dataset)}\")\n",
        "num_classes = len(train_dataset.class_names)\n",
        "\n",
        "# Compute class weights for Focal Loss\n",
        "total_samples = sum(class_counts)\n",
        "weights = [total_samples / (num_classes * count) for count in class_counts]\n",
        "weights = torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "# Use crossvit_15_240 as it performs better\n",
        "model = timm.create_model('crossvit_15_240', pretrained=True, num_classes=num_classes, drop_rate=0.4)  # Increased dropout\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(\"Model loaded on:\", device)\n"
      ],
      "metadata": {
        "id": "cAPrhFQh8wmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, train_loader, valid_loader, num_epochs=100, lr=0.0001):\n",
        "    optimizer = Adam(model.parameters(), lr=lr, weight_decay=5e-3)  # Increased weight decay\n",
        "    criterion = FocalLoss(gamma=2.0, weight=weights.to(device)).to(device)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "    scaler = GradScaler()  # For mixed precision training\n",
        "\n",
        "    # Early stopping parameters\n",
        "    best_val_loss = float('inf')\n",
        "    patience = 10\n",
        "    patience_counter = 0\n",
        "\n",
        "    # Freeze backbone initially\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    for param in model.head.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 5:  # Reduced freezing period\n",
        "            for param in model.parameters():\n",
        "                param.requires_grad = True\n",
        "            print(\"Unfreezing all layers\")\n",
        "            optimizer.param_groups[0]['lr'] = 0.00005\n",
        "\n",
        "        model.train()\n",
        "        train_loss, correct_train, total_train = 0.0, 0, 0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with autocast():  # Mixed precision training\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = correct_train / total_train\n",
        "\n",
        "        model.eval()\n",
        "        val_loss, correct_val, total_val = 0.0, 0, 0\n",
        "        all_preds, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                with autocast():\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct_val += (predicted == labels).sum().item()\n",
        "                total_val += labels.size(0)\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "        val_loss /= len(valid_loader.dataset)\n",
        "        val_acc = correct_val / total_val\n",
        "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "        per_class_f1 = f1_score(all_labels, all_preds, average=None)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}, \"\n",
        "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "        print(\"Per-class F1-scores:\", {train_dataset.class_names[i]: f1 for i, f1 in enumerate(per_class_f1)})\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "IXqtVk-X8wqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Evaluate\n",
        "history = train_and_evaluate(model, train_loader, valid_loader, num_epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "206a6bb9bcbe44808a691b1cc0afadc0",
            "8191d28d354844ee914ca7cf146f4c88",
            "c63bd26ab58a44f68328ce8480a099d7",
            "dd6df9774e4641fe8375edfc38fc717d",
            "2b95b083ef014145a96a2571918aa415",
            "f2c1330a7f8d41b38450ef56f41cb3e1",
            "aa862aa207544fa7b202c833c71d101d",
            "c93db02ceda04867b4939a6a2c884dcc",
            "c3964fba3fa7483eb8dd609823e9c825",
            "7a50f5ed721d4e1391d73c938e15acb3",
            "44373aa4b0f0413581dda791486c55a0"
          ]
        },
        "id": "igJoOu8Gm7_b",
        "outputId": "a1b0d609-ef4e-462d-b16b-807bb4a5fbba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images: 1176, Images with annotations: 1170\n",
            "Images missing annotations: 6. Example IDs: [73, 747, 785, 537, 1019]\n",
            "Class distribution: Counter({'Triple Bottom Reversal': 332, 'Ascending Triangle': 211, 'Symmetric Triangle': 177, 'Descending Triangle': 114, 'Head and Shoulder': 110, 'Double Top': 84, 'Inverse Head and Shoulder': 55, 'Cup and Handle': 40, 'Double Bottom': 23, 'flag-and-pole': 22, 'Falling Wedge': 2})\n",
            "Total images: 289, Images with annotations: 288\n",
            "Images missing annotations: 1. Example IDs: [52]\n",
            "Class distribution: Counter({'Triple Bottom Reversal': 77, 'Ascending Triangle': 68, 'Symmetric Triangle': 35, 'Descending Triangle': 31, 'Double Top': 23, 'Head and Shoulder': 17, 'Inverse Head and Shoulder': 14, 'Double Bottom': 12, 'Cup and Handle': 6, 'flag-and-pole': 5})\n",
            "Classes: ['flag-and-pole', 'Ascending Triangle', 'Cup and Handle', 'Descending Triangle', 'Double Bottom', 'Double Top', 'Falling Wedge', 'Head and Shoulder', 'Inverse Head and Shoulder', 'Symmetric Triangle', 'Triple Bottom Reversal', 'flag-and-pole']\n",
            "Training samples: 1170, Validation samples: 288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/110M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "206a6bb9bcbe44808a691b1cc0afadc0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:125: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # For mixed precision training\n",
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 3.5120, Train Acc: 0.0513, Val Loss: 1.7485, Val Acc: 0.0417, Val F1: 0.0041, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.08421052631578947), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100, Train Loss: 2.9733, Train Acc: 0.0479, Val Loss: 1.7235, Val Acc: 0.0278, Val F1: 0.0053, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.06060606060606061), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.058091286307053944), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100, Train Loss: 3.4351, Train Acc: 0.0607, Val Loss: 1.7081, Val Acc: 0.0486, Val F1: 0.0083, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.11851851851851852), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.06818181818181818), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100, Train Loss: 3.1830, Train Acc: 0.0436, Val Loss: 1.7001, Val Acc: 0.0312, Val F1: 0.0048, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.023668639053254437), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.10294117647058823), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100, Train Loss: 3.6283, Train Acc: 0.0598, Val Loss: 1.6939, Val Acc: 0.0312, Val F1: 0.0043, LR: 0.000100\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.014814814814814815), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.0963855421686747), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Unfreezing all layers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100, Train Loss: 2.9035, Train Acc: 0.0496, Val Loss: 1.6576, Val Acc: 0.0417, Val F1: 0.0037, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.08856088560885608), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100, Train Loss: 3.4493, Train Acc: 0.0667, Val Loss: 1.6763, Val Acc: 0.0417, Val F1: 0.0036, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.08759124087591241), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100, Train Loss: 3.6312, Train Acc: 0.0718, Val Loss: 1.6521, Val Acc: 0.0417, Val F1: 0.0035, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0), 'Descending Triangle': np.float64(0.08333333333333333), 'Double Bottom': np.float64(0.0), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.0), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100, Train Loss: 2.8146, Train Acc: 0.0829, Val Loss: 1.6315, Val Acc: 0.0764, Val F1: 0.0538, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.0625), 'Descending Triangle': np.float64(0.09852216748768473), 'Double Bottom': np.float64(0.2608695652173913), 'Double Top': np.float64(0.2857142857142857), 'Falling Wedge': np.float64(0.09523809523809523), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0392156862745098)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Train Loss: 2.5482, Train Acc: 0.1333, Val Loss: 1.5712, Val Acc: 0.0660, Val F1: 0.0435, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.06451612903225806), 'Cup and Handle': np.float64(0.058823529411764705), 'Descending Triangle': np.float64(0.1111111111111111), 'Double Bottom': np.float64(0.22727272727272727), 'Double Top': np.float64(0.16), 'Falling Wedge': np.float64(0.05128205128205128), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.06622516556291391)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100, Train Loss: 2.1998, Train Acc: 0.1701, Val Loss: 1.5458, Val Acc: 0.0764, Val F1: 0.0482, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.05555555555555555), 'Descending Triangle': np.float64(0.08695652173913043), 'Double Bottom': np.float64(0.3389830508474576), 'Double Top': np.float64(0.1111111111111111), 'Falling Wedge': np.float64(0.07692307692307693), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.06944444444444445)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100, Train Loss: 1.7636, Train Acc: 0.1949, Val Loss: 1.5211, Val Acc: 0.1319, Val F1: 0.0717, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.037037037037037035), 'Cup and Handle': np.float64(0.27906976744186046), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.2878787878787879), 'Double Top': np.float64(0.1), 'Falling Wedge': np.float64(0.24719101123595505), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100, Train Loss: 1.6305, Train Acc: 0.2752, Val Loss: 1.5157, Val Acc: 0.1146, Val F1: 0.0766, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.32558139534883723), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3148148148148148), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.16666666666666666), 'Head and Shoulder': np.float64(0.1111111111111111), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0), 'Triple Bottom Reversal': np.float64(0.06593406593406594)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100, Train Loss: 1.2741, Train Acc: 0.3128, Val Loss: 1.5537, Val Acc: 0.1424, Val F1: 0.0860, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.0), 'Ascending Triangle': np.float64(0.05714285714285714), 'Cup and Handle': np.float64(0.3508771929824561), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3300970873786408), 'Double Top': np.float64(0.1875), 'Falling Wedge': np.float64(0.16470588235294117), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.09375)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100, Train Loss: 0.9933, Train Acc: 0.3214, Val Loss: 1.5635, Val Acc: 0.1458, Val F1: 0.1134, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.08108108108108109), 'Ascending Triangle': np.float64(0.08695652173913043), 'Cup and Handle': np.float64(0.41379310344827586), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3333333333333333), 'Double Top': np.float64(0.20689655172413793), 'Falling Wedge': np.float64(0.1875), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100, Train Loss: 0.7881, Train Acc: 0.3692, Val Loss: 1.6863, Val Acc: 0.1250, Val F1: 0.0977, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.027777777777777776), 'Ascending Triangle': np.float64(0.03508771929824561), 'Cup and Handle': np.float64(0.3829787234042553), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3614457831325301), 'Double Top': np.float64(0.2564102564102564), 'Falling Wedge': np.float64(0.10638297872340426), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100, Train Loss: 0.7098, Train Acc: 0.3889, Val Loss: 1.6843, Val Acc: 0.1597, Val F1: 0.1435, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.20253164556962025), 'Ascending Triangle': np.float64(0.037037037037037035), 'Cup and Handle': np.float64(0.4262295081967213), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.35), 'Double Top': np.float64(0.18181818181818182), 'Falling Wedge': np.float64(0.19672131147540983), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0425531914893617)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100, Train Loss: 0.5955, Train Acc: 0.4376, Val Loss: 1.6802, Val Acc: 0.1354, Val F1: 0.1109, LR: 0.000050\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.15584415584415584), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.3829787234042553), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3368421052631579), 'Double Top': np.float64(0.0), 'Falling Wedge': np.float64(0.112), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.030303030303030304)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100, Train Loss: 0.4777, Train Acc: 0.4205, Val Loss: 1.8305, Val Acc: 0.2049, Val F1: 0.1783, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.32786885245901637), 'Ascending Triangle': np.float64(0.05263157894736842), 'Cup and Handle': np.float64(0.4), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.35135135135135137), 'Double Top': np.float64(0.27450980392156865), 'Falling Wedge': np.float64(0.17391304347826086), 'Head and Shoulder': np.float64(0.03278688524590164), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Train Loss: 0.3917, Train Acc: 0.5026, Val Loss: 1.7854, Val Acc: 0.2257, Val F1: 0.1874, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.3851851851851852), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.4666666666666667), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.35294117647058826), 'Double Top': np.float64(0.16), 'Falling Wedge': np.float64(0.17582417582417584), 'Head and Shoulder': np.float64(0.0), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100, Train Loss: 0.3488, Train Acc: 0.5291, Val Loss: 1.7893, Val Acc: 0.2465, Val F1: 0.2176, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.37209302325581395), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.4666666666666667), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3611111111111111), 'Double Top': np.float64(0.38095238095238093), 'Falling Wedge': np.float64(0.1978021978021978), 'Head and Shoulder': np.float64(0.041666666666666664), 'Inverse Head and Shoulder': np.float64(0.05063291139240506), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100, Train Loss: 0.3072, Train Acc: 0.5496, Val Loss: 1.8302, Val Acc: 0.2014, Val F1: 0.1655, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.32727272727272727), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.38461538461538464), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.3541666666666667), 'Double Top': np.float64(0.09523809523809523), 'Falling Wedge': np.float64(0.1774193548387097), 'Head and Shoulder': np.float64(0.03508771929824561), 'Inverse Head and Shoulder': np.float64(0.0), 'Symmetric Triangle': np.float64(0.0)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-50a572049e65>:152: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision training\n",
            "<ipython-input-2-50a572049e65>:173: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100, Train Loss: 0.2587, Train Acc: 0.5838, Val Loss: 1.8598, Val Acc: 0.2708, Val F1: 0.2201, LR: 0.000025\n",
            "Per-class F1-scores: {'flag-and-pole': np.float64(0.4528301886792453), 'Ascending Triangle': np.float64(0.0), 'Cup and Handle': np.float64(0.3404255319148936), 'Descending Triangle': np.float64(0.0), 'Double Bottom': np.float64(0.37333333333333335), 'Double Top': np.float64(0.32727272727272727), 'Falling Wedge': np.float64(0.2191780821917808), 'Head and Shoulder': np.float64(0.08163265306122448), 'Inverse Head and Shoulder': np.float64(0.02564102564102564), 'Symmetric Triangle': np.float64(0.0)}\n",
            "Early stopping at epoch 23\n"
          ]
        }
      ]
    }
  ]
}