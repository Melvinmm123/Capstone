{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TcT-EXjEcGz",
        "outputId": "e0a6e3f2-584c-439a-d0ce-c47d708e63ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import timm\n",
        "from torch import nn, optim\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Set locale environment variables\n",
        "os.environ['LC_ALL'] = 'C.UTF-8'\n",
        "os.environ['LANG'] = 'C.UTF-8'\n",
        "\n",
        "# Install the required packages\n",
        "!pip install torch torchvision timm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSOOFKFOEilW",
        "outputId": "6253e9c1-1e69-45d3-ece0-d76c31278862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.26.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to your datasets\n",
        "train_dir = '/content/drive/MyDrive/Deep learning/train_data/Graph Patterns'\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # CrossViT input size\n",
        "    transforms.ToTensor(),         # Convert image to tensor\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
        "\n",
        "# Split into training and validation\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Print class names\n",
        "class_names = dataset.classes\n",
        "print(\"Classes:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVy5OE9TEsS0",
        "outputId": "bbff7ef2-9ec7-4fb8-8022-475b01499299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Ascending Triangle', 'Cup and Handle', 'Descending Triangle', 'Double Bottom', 'Double Top', 'Falling Wedge', 'Flag', 'Head and Shoulders Top', 'Inverse Head and Shoulder', 'Rounding', 'Symmetrical Triangle', 'Triple Bottom Reversal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UnlabeledImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Custom dataset for loading images without labels.\n",
        "\n",
        "        Args:\n",
        "            root_dir (str): Path to the directory containing images.\n",
        "            transform (callable, optional): A function/transform to apply to the images.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = [\n",
        "            os.path.join(root_dir, fname)\n",
        "            for fname in os.listdir(root_dir)\n",
        "            if fname.endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_path  # Return image and its path for reference\n",
        "\n",
        "# Define test directory\n",
        "test_dir = '/content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos'\n",
        "\n",
        "# Create test dataset and DataLoader\n",
        "test_dataset = UnlabeledImageDataset(root_dir=test_dir, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Loaded {len(test_dataset)} test images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPbGNl5UEtCO",
        "outputId": "1b891885-a19d-4c7a-d19a-96505c42620a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 62 test images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Load CrossViT model\n",
        "model = timm.create_model('crossvit_15_240', pretrained=True, num_classes=num_classes)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(\"Model loaded on:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDerimlQEtFH",
        "outputId": "aa037da9-b3af-48ab-8ef0-68bf89d0fcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=100):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Training loop\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation loop\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = correct / total\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, num_epochs=100)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bnmqvqeEtHe",
        "outputId": "9c229af7-72a3-4bba-e4cb-bf1844c25eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Train Loss: 2.5354, Train Acc: 0.0533, Val Loss: 2.5103, Val Acc: 0.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100, Train Loss: 2.5118, Train Acc: 0.0667, Val Loss: 2.5046, Val Acc: 0.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100, Train Loss: 2.5225, Train Acc: 0.0733, Val Loss: 2.5156, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100, Train Loss: 2.4955, Train Acc: 0.1067, Val Loss: 2.5367, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100, Train Loss: 2.5011, Train Acc: 0.0800, Val Loss: 2.4980, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100, Train Loss: 2.4789, Train Acc: 0.0867, Val Loss: 2.4990, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100, Train Loss: 2.4681, Train Acc: 0.1067, Val Loss: 2.4986, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100, Train Loss: 2.4619, Train Acc: 0.1133, Val Loss: 2.5063, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100, Train Loss: 2.4543, Train Acc: 0.1133, Val Loss: 2.5047, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100, Train Loss: 2.4638, Train Acc: 0.1200, Val Loss: 2.5103, Val Acc: 0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100, Train Loss: 2.4543, Train Acc: 0.1200, Val Loss: 2.5195, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100, Train Loss: 2.4358, Train Acc: 0.1133, Val Loss: 2.5184, Val Acc: 0.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100, Train Loss: 2.4340, Train Acc: 0.1333, Val Loss: 2.5131, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100, Train Loss: 2.4098, Train Acc: 0.1267, Val Loss: 2.5053, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100, Train Loss: 2.4116, Train Acc: 0.1533, Val Loss: 2.6490, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100, Train Loss: 2.3764, Train Acc: 0.1067, Val Loss: 2.5945, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100, Train Loss: 2.4062, Train Acc: 0.1400, Val Loss: 2.6135, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100, Train Loss: 2.3817, Train Acc: 0.1333, Val Loss: 2.6075, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100, Train Loss: 2.3478, Train Acc: 0.1400, Val Loss: 2.5232, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100, Train Loss: 2.2761, Train Acc: 0.1733, Val Loss: 2.5574, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100, Train Loss: 2.2084, Train Acc: 0.2067, Val Loss: 2.6059, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100, Train Loss: 2.1592, Train Acc: 0.2333, Val Loss: 2.6348, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100, Train Loss: 2.1157, Train Acc: 0.2600, Val Loss: 2.7216, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100, Train Loss: 2.1117, Train Acc: 0.2533, Val Loss: 2.5807, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100, Train Loss: 2.0549, Train Acc: 0.2333, Val Loss: 2.8073, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100, Train Loss: 1.9513, Train Acc: 0.3133, Val Loss: 2.7151, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100, Train Loss: 1.8156, Train Acc: 0.3600, Val Loss: 2.7367, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100, Train Loss: 1.7463, Train Acc: 0.3600, Val Loss: 2.7896, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100, Train Loss: 1.6145, Train Acc: 0.4200, Val Loss: 2.8342, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100, Train Loss: 1.5403, Train Acc: 0.4133, Val Loss: 2.9941, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100, Train Loss: 1.5101, Train Acc: 0.4400, Val Loss: 2.9653, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100, Train Loss: 1.4142, Train Acc: 0.4733, Val Loss: 3.3543, Val Acc: 0.0526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100, Train Loss: 1.4241, Train Acc: 0.4867, Val Loss: 3.6343, Val Acc: 0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100, Train Loss: 1.4611, Train Acc: 0.4667, Val Loss: 3.5093, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100, Train Loss: 1.4105, Train Acc: 0.4800, Val Loss: 3.5710, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100, Train Loss: 1.4033, Train Acc: 0.4467, Val Loss: 3.8632, Val Acc: 0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/100, Train Loss: 1.3391, Train Acc: 0.5200, Val Loss: 3.6031, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/100, Train Loss: 1.1811, Train Acc: 0.5467, Val Loss: 3.9068, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/100, Train Loss: 1.1925, Train Acc: 0.5800, Val Loss: 4.0411, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/100, Train Loss: 1.0832, Train Acc: 0.6000, Val Loss: 4.3343, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/100, Train Loss: 1.0175, Train Acc: 0.6133, Val Loss: 4.1221, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/100, Train Loss: 0.9675, Train Acc: 0.6400, Val Loss: 4.2945, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/100, Train Loss: 0.9437, Train Acc: 0.6333, Val Loss: 3.9577, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/100, Train Loss: 0.9282, Train Acc: 0.6400, Val Loss: 3.8375, Val Acc: 0.3158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/100, Train Loss: 0.9925, Train Acc: 0.6400, Val Loss: 4.3252, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/100, Train Loss: 0.9576, Train Acc: 0.6400, Val Loss: 4.2127, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/100, Train Loss: 0.8035, Train Acc: 0.7267, Val Loss: 4.2223, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/100, Train Loss: 0.6548, Train Acc: 0.7467, Val Loss: 4.3728, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/100, Train Loss: 0.5908, Train Acc: 0.8200, Val Loss: 4.4638, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/100, Train Loss: 0.6072, Train Acc: 0.8000, Val Loss: 4.5610, Val Acc: 0.2368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/100, Train Loss: 0.7479, Train Acc: 0.7400, Val Loss: 4.5606, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/100, Train Loss: 0.9818, Train Acc: 0.6400, Val Loss: 4.8869, Val Acc: 0.2632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/100, Train Loss: 1.0811, Train Acc: 0.6200, Val Loss: 4.6337, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/100, Train Loss: 0.8586, Train Acc: 0.6733, Val Loss: 4.5895, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/100, Train Loss: 0.7687, Train Acc: 0.7333, Val Loss: 4.3589, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/100, Train Loss: 0.6430, Train Acc: 0.7933, Val Loss: 4.5323, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/100, Train Loss: 0.5223, Train Acc: 0.8133, Val Loss: 4.8990, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/100, Train Loss: 0.6294, Train Acc: 0.7933, Val Loss: 4.9577, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/100, Train Loss: 0.5233, Train Acc: 0.8133, Val Loss: 5.0578, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/100, Train Loss: 0.4871, Train Acc: 0.8267, Val Loss: 4.7670, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/100, Train Loss: 0.5046, Train Acc: 0.8267, Val Loss: 4.9793, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/100, Train Loss: 0.4398, Train Acc: 0.8333, Val Loss: 5.0837, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/100, Train Loss: 0.3291, Train Acc: 0.9000, Val Loss: 5.0737, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/100, Train Loss: 0.3062, Train Acc: 0.9133, Val Loss: 4.9583, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/100, Train Loss: 0.3051, Train Acc: 0.9133, Val Loss: 5.2885, Val Acc: 0.2368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/100, Train Loss: 0.2739, Train Acc: 0.9267, Val Loss: 5.2441, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/100, Train Loss: 0.2104, Train Acc: 0.9333, Val Loss: 5.6925, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/100, Train Loss: 0.2326, Train Acc: 0.9267, Val Loss: 5.5103, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/100, Train Loss: 0.2150, Train Acc: 0.9200, Val Loss: 5.5361, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/100, Train Loss: 0.1447, Train Acc: 0.9667, Val Loss: 5.6462, Val Acc: 0.2368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/100, Train Loss: 0.1465, Train Acc: 0.9667, Val Loss: 5.6726, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/100, Train Loss: 0.1304, Train Acc: 0.9533, Val Loss: 5.8861, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/100, Train Loss: 0.1511, Train Acc: 0.9467, Val Loss: 6.0169, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/100, Train Loss: 0.1823, Train Acc: 0.9333, Val Loss: 5.7786, Val Acc: 0.2368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/100, Train Loss: 0.1363, Train Acc: 0.9667, Val Loss: 5.9998, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76/100, Train Loss: 0.0914, Train Acc: 0.9800, Val Loss: 5.6526, Val Acc: 0.2632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77/100, Train Loss: 0.2906, Train Acc: 0.9133, Val Loss: 5.9798, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78/100, Train Loss: 0.5689, Train Acc: 0.7933, Val Loss: 5.6949, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79/100, Train Loss: 0.6312, Train Acc: 0.7867, Val Loss: 6.2288, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80/100, Train Loss: 1.1911, Train Acc: 0.6733, Val Loss: 5.5806, Val Acc: 0.2368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81/100, Train Loss: 1.1008, Train Acc: 0.6667, Val Loss: 5.0039, Val Acc: 0.1842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82/100, Train Loss: 0.6081, Train Acc: 0.8467, Val Loss: 5.5821, Val Acc: 0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83/100, Train Loss: 0.6229, Train Acc: 0.8067, Val Loss: 5.2580, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84/100, Train Loss: 0.6099, Train Acc: 0.8267, Val Loss: 5.1666, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85/100, Train Loss: 0.4780, Train Acc: 0.8333, Val Loss: 5.1856, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86/100, Train Loss: 0.2784, Train Acc: 0.9000, Val Loss: 5.1994, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87/100, Train Loss: 0.2583, Train Acc: 0.9467, Val Loss: 5.3356, Val Acc: 0.2105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88/100, Train Loss: 0.1538, Train Acc: 0.9600, Val Loss: 5.8042, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89/100, Train Loss: 0.1677, Train Acc: 0.9533, Val Loss: 5.8598, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90/100, Train Loss: 0.1196, Train Acc: 0.9533, Val Loss: 5.9778, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91/100, Train Loss: 0.0935, Train Acc: 0.9800, Val Loss: 6.0896, Val Acc: 0.1316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92/100, Train Loss: 0.0631, Train Acc: 0.9733, Val Loss: 6.1352, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93/100, Train Loss: 0.0575, Train Acc: 0.9800, Val Loss: 6.1561, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94/100, Train Loss: 0.0470, Train Acc: 0.9867, Val Loss: 6.1961, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95/100, Train Loss: 0.0428, Train Acc: 0.9867, Val Loss: 6.2062, Val Acc: 0.1579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96/100, Train Loss: 0.0350, Train Acc: 1.0000, Val Loss: 6.2189, Val Acc: 0.1053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97/100, Train Loss: 0.0335, Train Acc: 0.9933, Val Loss: 6.2386, Val Acc: 0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98/100, Train Loss: 0.0364, Train Acc: 0.9933, Val Loss: 6.2398, Val Acc: 0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99/100, Train Loss: 0.0272, Train Acc: 0.9933, Val Loss: 6.2579, Val Acc: 0.0789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/100, Train Loss: 0.0301, Train Acc: 0.9933, Val Loss: 6.2501, Val Acc: 0.1316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_on_unlabeled_data(model, test_loader, class_names):\n",
        "    \"\"\"\n",
        "    Perform inference on unlabeled test images.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch model.\n",
        "        test_loader: DataLoader for test dataset.\n",
        "        class_names: List of class names corresponding to class indices.\n",
        "\n",
        "    Returns:\n",
        "        predictions: List of tuples (image_path, predicted_class, confidence_score).\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, img_paths in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            conf, predicted = torch.max(probabilities, 1)  # Get predicted class and confidence\n",
        "            for i in range(len(img_paths)):\n",
        "                predictions.append((img_paths[i], class_names[predicted[i].item()], conf[i].item()))\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Run inference\n",
        "predictions = test_model_on_unlabeled_data(model, test_loader, class_names)\n",
        "\n",
        "# Print results\n",
        "for img_path, pred_class, conf in predictions:\n",
        "    print(f\"Image: {img_path} | Predicted Class: {pred_class} | Confidence: {conf:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfa28iYNEtKC",
        "outputId": "3bc7cd4b-81d2-483e-980f-29de5bfa681a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3061_to_3150.png | Predicted Class: Cup and Handle | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2161_to_2250.png | Predicted Class: Descending Triangle | Confidence: 0.65\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_181_to_270.png | Predicted Class: Cup and Handle | Confidence: 0.64\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2431_to_2520.png | Predicted Class: Ascending Triangle | Confidence: 0.92\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5401_to_5490.png | Predicted Class: Symmetrical Triangle | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4051_to_4140.png | Predicted Class: Descending Triangle | Confidence: 0.49\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1081_to_1170.png | Predicted Class: Symmetrical Triangle | Confidence: 0.79\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1_to_90.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.50\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1171_to_1260.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.89\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_631_to_720.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4501_to_4590.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.90\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3511_to_3600.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.93\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1711_to_1800.png | Predicted Class: Cup and Handle | Confidence: 0.77\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2341_to_2430.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.79\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4411_to_4500.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.77\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3691_to_3780.png | Predicted Class: Cup and Handle | Confidence: 0.99\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_901_to_990.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.59\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1801_to_1890.png | Predicted Class: Ascending Triangle | Confidence: 0.48\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4681_to_4770.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.89\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1531_to_1620.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.62\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3151_to_3240.png | Predicted Class: Ascending Triangle | Confidence: 0.70\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5131_to_5220.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.52\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_811_to_900.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.87\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3421_to_3510.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.75\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2521_to_2610.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.87\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2071_to_2160.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.75\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_541_to_630.png | Predicted Class: Symmetrical Triangle | Confidence: 0.80\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1981_to_2070.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.46\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3241_to_3330.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5311_to_5400.png | Predicted Class: Symmetrical Triangle | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1261_to_1350.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.54\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2701_to_2790.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.58\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4231_to_4320.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.66\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3601_to_3690.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.78\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2251_to_2340.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.73\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1891_to_1980.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.63\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4771_to_4860.png | Predicted Class: Falling Wedge | Confidence: 0.88\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4951_to_5040.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.85\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2881_to_2970.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.94\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3871_to_3960.png | Predicted Class: Cup and Handle | Confidence: 0.84\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4861_to_4950.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2791_to_2880.png | Predicted Class: Cup and Handle | Confidence: 0.60\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4141_to_4230.png | Predicted Class: Symmetrical Triangle | Confidence: 0.84\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1441_to_1530.png | Predicted Class: Symmetrical Triangle | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_361_to_450.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.69\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5041_to_5130.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.51\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3961_to_4050.png | Predicted Class: Cup and Handle | Confidence: 0.49\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4321_to_4410.png | Predicted Class: Ascending Triangle | Confidence: 0.93\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_451_to_540.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.96\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3781_to_3870.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_271_to_360.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.93\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3331_to_3420.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.91\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1351_to_1440.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_991_to_1080.png | Predicted Class: Cup and Handle | Confidence: 0.76\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_91_to_180.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.53\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5221_to_5310.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.94\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1621_to_1710.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2611_to_2700.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.81\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_721_to_810.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.82\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2971_to_3060.png | Predicted Class: Cup and Handle | Confidence: 0.82\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5491_to_5580.png | Predicted Class: Descending Triangle | Confidence: 0.60\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4591_to_4680.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_confidence_scores_and_intervals(model, data_loader, class_names, confidence_interval=0.95):\n",
        "    \"\"\"\n",
        "    Computes confidence scores for predictions and calculates confidence intervals.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): Trained model for inference.\n",
        "        data_loader (DataLoader): DataLoader for the test dataset.\n",
        "        class_names (list): List of class names corresponding to class indices.\n",
        "        confidence_interval (float): Desired confidence interval (default is 0.95).\n",
        "\n",
        "    Returns:\n",
        "        dict: Contains:\n",
        "            - predictions: List of tuples (image_path, predicted_class, confidence_score).\n",
        "            - confidence_summary: Dictionary with mean, min, max, and confidence interval bounds.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    confidence_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, img_paths in data_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)  # Compute probabilities\n",
        "            conf, predicted = torch.max(probabilities, 1)  # Confidence and predicted class\n",
        "\n",
        "            for i in range(len(img_paths)):\n",
        "                score = conf[i].item()\n",
        "                confidence_scores.append(score)\n",
        "                predictions.append((img_paths[i], class_names[predicted[i].item()], score))\n",
        "\n",
        "    # Compute statistics for confidence scores\n",
        "    mean_conf = np.mean(confidence_scores)\n",
        "    std_dev = np.std(confidence_scores, ddof=1)\n",
        "    n = len(confidence_scores)\n",
        "    z = norm.ppf((1 + confidence_interval) / 2)  # Z-score for the confidence interval\n",
        "    margin_of_error = z * (std_dev / np.sqrt(n))\n",
        "    lower_bound = mean_conf - margin_of_error\n",
        "    upper_bound = mean_conf + margin_of_error\n",
        "\n",
        "    confidence_summary = {\n",
        "        \"mean_confidence\": mean_conf,\n",
        "        \"min_confidence\": np.min(confidence_scores),\n",
        "        \"max_confidence\": np.max(confidence_scores),\n",
        "        \"confidence_interval\": (lower_bound, upper_bound),\n",
        "    }\n",
        "\n",
        "    return {\"predictions\": predictions, \"confidence_summary\": confidence_summary}\n"
      ],
      "metadata": {
        "id": "xR7hEuMvFKuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = compute_confidence_scores_and_intervals(model, test_loader, class_names)\n",
        "\n",
        "# Extract predictions and confidence summary\n",
        "predictions = results[\"predictions\"]\n",
        "confidence_summary = results[\"confidence_summary\"]\n",
        "\n",
        "# Print predictions\n",
        "for img_path, pred_class, conf in predictions:\n",
        "    print(f\"Image: {img_path} | Predicted Class: {pred_class} | Confidence: {conf:.2f}\")\n",
        "\n",
        "# Print confidence summary\n",
        "print(\"\\nConfidence Summary:\")\n",
        "print(f\"Mean Confidence: {confidence_summary['mean_confidence']:.2f}\")\n",
        "print(f\"Min Confidence: {confidence_summary['min_confidence']:.2f}\")\n",
        "print(f\"Max Confidence: {confidence_summary['max_confidence']:.2f}\")\n",
        "print(f\"Confidence Interval (95%): {confidence_summary['confidence_interval']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQf0Dqg2FK3J",
        "outputId": "490466ca-d56b-445a-95cf-125125eb5dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3061_to_3150.png | Predicted Class: Cup and Handle | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2161_to_2250.png | Predicted Class: Descending Triangle | Confidence: 0.65\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_181_to_270.png | Predicted Class: Cup and Handle | Confidence: 0.64\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2431_to_2520.png | Predicted Class: Ascending Triangle | Confidence: 0.92\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5401_to_5490.png | Predicted Class: Symmetrical Triangle | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4051_to_4140.png | Predicted Class: Descending Triangle | Confidence: 0.49\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1081_to_1170.png | Predicted Class: Symmetrical Triangle | Confidence: 0.79\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1_to_90.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.50\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1171_to_1260.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.89\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_631_to_720.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4501_to_4590.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.90\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3511_to_3600.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.93\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1711_to_1800.png | Predicted Class: Cup and Handle | Confidence: 0.77\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2341_to_2430.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.79\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4411_to_4500.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.77\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3691_to_3780.png | Predicted Class: Cup and Handle | Confidence: 0.99\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_901_to_990.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.59\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1801_to_1890.png | Predicted Class: Ascending Triangle | Confidence: 0.48\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4681_to_4770.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.89\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1531_to_1620.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.62\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3151_to_3240.png | Predicted Class: Ascending Triangle | Confidence: 0.70\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5131_to_5220.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.52\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_811_to_900.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.87\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3421_to_3510.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.75\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2521_to_2610.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.87\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2071_to_2160.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.75\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_541_to_630.png | Predicted Class: Symmetrical Triangle | Confidence: 0.80\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1981_to_2070.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.46\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3241_to_3330.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5311_to_5400.png | Predicted Class: Symmetrical Triangle | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1261_to_1350.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.54\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2701_to_2790.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.58\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4231_to_4320.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.66\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3601_to_3690.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.78\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2251_to_2340.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.73\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1891_to_1980.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.63\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4771_to_4860.png | Predicted Class: Falling Wedge | Confidence: 0.88\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4951_to_5040.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.85\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2881_to_2970.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.94\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3871_to_3960.png | Predicted Class: Cup and Handle | Confidence: 0.84\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4861_to_4950.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2791_to_2880.png | Predicted Class: Cup and Handle | Confidence: 0.60\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4141_to_4230.png | Predicted Class: Symmetrical Triangle | Confidence: 0.84\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1441_to_1530.png | Predicted Class: Symmetrical Triangle | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_361_to_450.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.69\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5041_to_5130.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.51\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3961_to_4050.png | Predicted Class: Cup and Handle | Confidence: 0.49\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4321_to_4410.png | Predicted Class: Ascending Triangle | Confidence: 0.93\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_451_to_540.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.96\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3781_to_3870.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.97\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_271_to_360.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.93\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_3331_to_3420.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.91\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1351_to_1440.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_991_to_1080.png | Predicted Class: Cup and Handle | Confidence: 0.76\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_91_to_180.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.53\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5221_to_5310.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.94\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_1621_to_1710.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.95\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2611_to_2700.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.81\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_721_to_810.png | Predicted Class: Inverse Head and Shoulder | Confidence: 0.82\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_2971_to_3060.png | Predicted Class: Cup and Handle | Confidence: 0.82\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_5491_to_5580.png | Predicted Class: Descending Triangle | Confidence: 0.60\n",
            "Image: /content/drive/MyDrive/Deep learning/test_data/Nvidia_3Mos/NVDA_2000_to_2021_4591_to_4680.png | Predicted Class: Triple Bottom Reversal | Confidence: 0.93\n",
            "\n",
            "Confidence Summary:\n",
            "Mean Confidence: 0.78\n",
            "Min Confidence: 0.46\n",
            "Max Confidence: 0.99\n",
            "Confidence Interval (95%): (0.7417002940840387, 0.8228854262550904)\n"
          ]
        }
      ]
    }
  ]
}